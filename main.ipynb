{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осоргин Иван БКЛ211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib transformers ipywidgets pandas\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'CommitmentBank-items.csv'\n",
    "with open(filename, 'r') as f:\n",
    "    colnames = next(csv.reader(f))\n",
    "\n",
    "def rows_gen():\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        _ = next(reader)\n",
    "        for row in reader:\n",
    "            yield {k: v for k, v in zip(colnames, row)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Tuple, Dict\n",
    "predicates = {}\n",
    "categories = ['modal', 'conditional', 'negation', 'question']\n",
    "# counting occurances\n",
    "for r in rows_gen():\n",
    "    if not r['Verb'] in predicates:\n",
    "        predicates[r['Verb']] = defaultdict(list)\n",
    "    for category in categories:\n",
    "        if category in r['Embedding']:\n",
    "            predicates[r['Verb']][category].append(float(r['Mean']))\n",
    "# counting average for each\n",
    "for p in predicates.keys():\n",
    "    for c in categories:\n",
    "        l = len(predicates[p][c])\n",
    "        if l == 0: \n",
    "            del predicates[p][c]\n",
    "            continue\n",
    "        predicates[p][c] = (sum(predicates[p][c]) / l, l)\n",
    "# restructuring data to list of tuples\n",
    "predicates = [(k, dict(v)) for k, v in predicates.items()]\n",
    "# filtering out predicates that have less than `treshold` occurences\n",
    "def enough(predicate: Tuple[str, Dict[str, Tuple[float, int]]]) -> bool:\n",
    "    treshold = 2\n",
    "    for _, it in predicate[1].items():\n",
    "        if it[1] < treshold:\n",
    "            return False\n",
    "    return True\n",
    "print(f\"Size before: {len(predicates)};\", end=' ')\n",
    "predicates = [p for p in predicates if enough(p)]\n",
    "print(f\"after: {len(predicates)}\")\n",
    "# sorting by mean modality\n",
    "predicates.sort(key=lambda x: sum([i[0] for i in x[1].values()]) / len(x[1]))\n",
    "predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xticks(ticks=[i for i in range(len(predicates))],\n",
    "           labels=[p[0] for p in predicates],\n",
    "           rotation=50)\n",
    "plt.ylim(-3.3, 3.3)\n",
    "\n",
    "colors = ['r', 'g', 'b', 'black']\n",
    "markers = ['$M$', '$C$', '$N$', '$Q$']\n",
    "for cat, col, mar in zip(categories, colors, markers):\n",
    "    y_data = [it[cat][0] if cat in it else 0 for _, it in predicates]\n",
    "    plt.plot(y_data, color=col, marker=mar, linewidth=1, markersize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Источник | Предикат | Тип | Контекст | Цель | Рейтинг |\n",
    "|---|---|---|---|---|---|\n",
    "| НКРЯ \\| [Наши дети: Подростки (2004)] | решить | ничего | Но дело в том, что если в книге будет рассказано в таком стиле, вроде сказочных персонажей, объясняющих как и что надо делать, думаю меня ребенок просто засмеет.  Сейчас другие приоритеты. | Он решит, что я свихнулась. | -2 |\n",
    "| НКРЯ \\| [Запись LiveJournal (2004)] | сказать | ничего | Еще сегодня один знакомый из Туниса навел меня на интересную мысль по поводу манер. | Он в разговоре сказал, что всегда открывает девушке дверь машины и помогает сесть, но при этом в душе он ждет, что пока он обходит машину, она изнутри тоже откроет ему дверь, по крайней мере приоткроет. | 2 |\n",
    "| НКРЯ \\| [Андрей Митьков. Мороз по коже. Этап Кубка мира по лыжам в Токсове провели в экстремальных погодных условиях // «Известия», 2003.01.08] | знать | отрицание | Однако на старт в Токсове вышли только три суперзвезды из шести заявленных. | Организаторы не знали, что Бельмондо торжественно проводили из спорта еще весной 2002 года. | 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing NLI dataset\n",
    "with open('dataset.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(('sentence', 'label'))\n",
    "    for r in rows_gen():\n",
    "        mean = float(r['Mean'])\n",
    "        if mean <= -1: label = 'contradiction'\n",
    "        elif mean >= 1: label = 'entailment'\n",
    "        else: label = 'neutral'\n",
    "        writer.writerow((\n",
    "            f\"{r['Context']} {r['Target']}\",\n",
    "            label\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn, argmax, no_grad\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 3\n",
    "classifier = nn.Linear(768, num_labels)\n",
    "model = nn.Sequential(model, classifier)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDataSet(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.df.sentence[index], self.df.label[index]\n",
    "data_set = CsvDataSet('dataset.csv')\n",
    "train_size = int(0.8 * len(data_set))\n",
    "test_size = len(data_set) - train_size\n",
    "train_set, test_set = random_split(data_set, [train_size, test_size])\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        sentences, labels = batch\n",
    "        encoded_input = tokenizer(sentences, return_tensors='pt')\n",
    "        outputs = model(encoded_input)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Training loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    with no_grad():\n",
    "        for batch in test_loader:\n",
    "            sentences, labels = batch\n",
    "            outputs = model(sentences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            predictions = argmax(outputs, dim=1)\n",
    "            total_acc += (predictions == labels).sum().item()\n",
    "\n",
    "    print(f'Test loss: {total_loss/len(test_loader)} Test acc: {total_acc/len(test_set)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\"Hello I'm a [MASK] model.\", return_tensors='pt')\n",
    "outputs = model(**encoded_input)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    train(model, optimizer, train_loader, criterion)\n",
    "    evaluate(model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
